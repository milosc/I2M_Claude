## 1. The "Project-Level Context" Strategy

To keep AI agents or IDE tools (like Cursor, GitHub Copilot, or Windsurf) synchronized, you need a **Context Manifest**. This is a set of Markdown files stored in Git that the AI is instructed to read before every task.

* **`.context/sequences.md`**: A central file tracking the last used ID for User Stories (US), Jobs-to-be-Done (JBTD), and Tests (TST).
* **`.context/active_work.md`**: A summary of what each branch is currently doing.

**How it works in a team:**

1. Developer A pulls from Git.
2. The AI reads the local `.context/sequences.md`.
3. When the AI generates a new artifact (e.g., `US-105`), it **must** update the local file.
4. Developer A pushes the change.
5. If Developer B tries to use `US-105` simultaneously, Git will throw a **merge conflict** on the sequence file, forcing the team to reconcile the numbering.

---

## 2. The Database-Driven Pipeline (Stateful API)

If your team is building a custom AI pipeline (using LangChain, LlamaIndex, or a custom internal tool), you should move away from local files and use a **centralized State Store**.

Instead of the AI guessing the next ID, your pipeline should use a "Tool" or "Function Call" to interact with a database.

* **The Workflow:**
* Developer triggers the AI.
* The AI agent calls a `get_next_artifact_id()` function.
* The function queries a **Redis** or **PostgreSQL** DB that is shared by the whole team.
* The DB increments the ID and "locks" it, ensuring Developer B gets the next unique number.



---

## 3. The "Git-as-Backend" Strategy (Eventual Consistency)

If you don't want a separate database, you can treat Git as the single source of truth for state. This is common in "Agentic Workflows."

| Component | Shared State Management |
| --- | --- |
| **Artifact IDs** | AI scans the current directory for the highest existing number (e.g., `ls US-*.md`) before creating a new one. |
| **State Sync** | Frequent "Micro-commits." Developers push documentation/specs as soon as they are generated by AI. |
| **Conflict Resolution** | Use a `pre-commit` hook that runs a script to check for duplicate IDs across the repository. |

---


While Git is excellent for "Eventual Consistency" (merging code changes), it is too slow to handle "Real-time State" (preventing two developers from using the same ID at the same time). MCP acts as the **live bridge** between your team's individual AI clients and a single, shared source of truth.

### How MCP Solves the "Shared State" Problem

Instead of the AI looking at local files to "guess" the next artifact number, you move that logic to a **Centralized MCP Server**.

| Feature | Without MCP (Git Only) | With MCP (Centralized) |
| --- | --- | --- |
| **Source of Truth** | Local file system (stale until pull) | Live Database/API via MCP |
| **ID Allocation** | AI increments local highest number | AI calls `get_next_id()` tool |
| **Race Conditions** | High (Two devs create `US-105` simultaneously) | Zero (Server locks the ID during request) |
| **Context Sync** | Requires manual `git pull` | Instant access to team-wide metadata |

---

### The Workflow: Synchronized Artifact Numbering

With an MCP integration, your team's development loop changes from "Read-Write-Push" to "Query-Act-Log":

1. **The Request:** A developer on Machine A asks their AI: *"Create a new User Story for the login feature."*
2. **The Tool Call:** The AI (acting as an **MCP Client**) sees a tool called `get_new_artifact_id` provided by your **MCP Server**.
3. **The Server Logic:** Your MCP server (running on a central VPS or internal cloud) queries a small database (like SQLite or Redis). It sees the last ID was `US-105`, increments it to `US-106`, and returns it to the AI.
4. **The Result:** The AI generates the artifact as `US-106` on Machine A.
5. **Concurrent Request:** If a developer on Machine B makes the same request 1 second later, the MCP server returns `US-107` immediatelyâ€”**even if Machine A hasn't committed to Git yet.**

---

### Implementation Strategy

To set this up for your team, you would follow these steps:

#### 1. Host a Remote MCP Server

While most people use MCP locally (pointing to a local Python script), you can host an MCP server over **HTTP/SSE**. This allows every team member's IDE (Cursor, VS Code, etc.) to point to the same URL: `https://mcp.your-company.com`.

#### 2. Create "Stateful" Tools

Your MCP server would expose specific tools designed for state management:

* `reserve_next_id(type: "US" | "JBTD" | "TST")`: Increments a counter and returns the ID.
* `get_project_status()`: Returns a summary of what other team members are currently working on (based on active branch names or Jira status).
* `log_artifact_metadata(id, title, author)`: Records that an ID has been claimed.

#### 3. Use the GitHub/Jira MCP Servers

You don't even have to build this from scratch. There are official **GitHub MCP Servers** that allow the AI to directly query and create Issues or PRs. If you use GitHub Issues as your source of truth for `US-xyz`, the AI can simply create the issue via MCP and use the resulting Issue Number as the artifact ID.

### The Result

The AI becomes "team-aware." It no longer acts as a solo developer working in a vacuum; it acts as a connected agent that checks in with a central "registry" before making naming or numbering decisions.


